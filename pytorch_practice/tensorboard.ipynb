{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/mnist1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  )\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = examples.next()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "#writer.close()\n",
    "#sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TENSORBOARD ########################\n",
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "#writer.close()\n",
    "#sys.exit()\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/938], Loss: 0.2998\n",
      "Epoch [1/1], Step [200/938], Loss: 0.3571\n",
      "Epoch [1/1], Step [300/938], Loss: 0.4302\n",
      "Epoch [1/1], Step [400/938], Loss: 0.2142\n",
      "Epoch [1/1], Step [500/938], Loss: 0.1684\n",
      "Epoch [1/1], Step [600/938], Loss: 0.2448\n",
      "Epoch [1/1], Step [700/938], Loss: 0.2145\n",
      "Epoch [1/1], Step [800/938], Loss: 0.1162\n",
      "Epoch [1/1], Step [900/938], Loss: 0.1949\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            ############## TENSORBOARD ########################\n",
    "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
    "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
    "            running_correct = 0\n",
    "            running_loss = 0.0\n",
    "            ###################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a90884fd183d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Loss and optimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "class_labels = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        values, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
    "\n",
    "        class_preds.append(class_probs_batch)\n",
    "        class_labels.append(predicted)\n",
    "\n",
    "    # 10000, 10, and 10000, 1\n",
    "    # stack concatenates tensors along a new dimension\n",
    "    # cat concatenates tensors in the given dimension\n",
    "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
    "    class_labels = torch.cat(class_labels)\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "\n",
    "    ############## TENSORBOARD ########################\n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = class_labels == i\n",
    "        preds_i = class_preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()\n",
    "    ###################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
