{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "input_size = 28*28\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# load MNIST data\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                transform=transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example images\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 2, step 100/600, loss = 0.3210\n",
      "epoch 1 / 2, step 200/600, loss = 0.3804\n",
      "epoch 1 / 2, step 300/600, loss = 0.3294\n",
      "epoch 1 / 2, step 400/600, loss = 0.1819\n",
      "epoch 1 / 2, step 500/600, loss = 0.2442\n",
      "epoch 1 / 2, step 600/600, loss = 0.3304\n",
      "epoch 2 / 2, step 100/600, loss = 0.1360\n",
      "epoch 2 / 2, step 200/600, loss = 0.1790\n",
      "epoch 2 / 2, step 300/600, loss = 0.2015\n",
      "epoch 2 / 2, step 400/600, loss = 0.1740\n",
      "epoch 2 / 2, step 500/600, loss = 0.3458\n",
      "epoch 2 / 2, step 600/600, loss = 0.1789\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # (100, 1, 28, 28) -> (100, 784)\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print progress\n",
    "        if (i+1)%100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 95.15\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (pred == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct/ n_samples\n",
    "    print(f'accuracy = {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
