{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python271264bit09ab962d39a54180a5cb0c0e2dfff958",
   "display_name": "Python 2.7.12 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.1243,  1.0740,  0.9862], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0.0154, 0.7728, 0.6955], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = torch.sin(x)**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.0820,  0.2793,  0.3068])\n"
     ]
    }
   ],
   "source": [
    "y = torch.mean(y)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stop grad tracking 1\n",
    "# x.requires_grad_(False)\n",
    "# print(x)\n",
    "\n",
    "# # stop grad tracking 2\n",
    "# y = x.detach()\n",
    "\n",
    "# # stop grad tracking 3\n",
    "# with torch.no_grad():\n",
    "\n",
    "# # grad 초기화\n",
    "# x.grad.zero_()\n",
    "\n",
    "# optimizer = torch.optim.SGD(weights, lr = 0.001)\n",
    "# optimizer.step()\n",
    "# optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 2 : w = 1.150, b = 0.410, loss = 18.415\nepoch 12 : w = 2.051, b = 0.795, loss = 0.013\nepoch 22 : w = 2.050, b = 0.853, loss = 0.004\nepoch 32 : w = 2.037, b = 0.892, loss = 0.002\nepoch 42 : w = 2.027, b = 0.920, loss = 0.001\nepoch 52 : w = 2.020, b = 0.941, loss = 0.001\nepoch 62 : w = 2.015, b = 0.956, loss = 0.000\nepoch 72 : w = 2.011, b = 0.968, loss = 0.000\nepoch 82 : w = 2.008, b = 0.976, loss = 0.000\nepoch 92 : w = 2.006, b = 0.983, loss = 0.000\nprediction for f(5) : 11.010\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([3, 5, 7, 9], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0, dtype=torch.float32, requires_grad=True)\n",
    "b = torch.tensor(0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x +b\n",
    "\n",
    "def loss(y_pred, y_train):\n",
    "    return ((y_pred - y_train)**2).mean()\n",
    "\n",
    "lr = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in xrange(n_iters):\n",
    "    y_pred = forward(X)\n",
    "    l = loss(y_pred, y)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    if epoch%10 -1 == 0:\n",
    "        print(\"epoch %d : w = %.3f, b = %.3f, loss = %.3f\"%(epoch+1, w.item(), b.item(), l.item()))\n",
    "print(\"prediction for f(5) : %.3f\"%(forward(5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4, 1)\n",
      "epoch 100 : w = 1.958, b = 1.123, loss = 0.003\n",
      "epoch 200 : w = 1.969, b = 1.091, loss = 0.001\n",
      "epoch 300 : w = 1.977, b = 1.068, loss = 0.001\n",
      "epoch 400 : w = 1.983, b = 1.050, loss = 0.000\n",
      "epoch 500 : w = 1.987, b = 1.037, loss = 0.000\n",
      "epoch 600 : w = 1.991, b = 1.027, loss = 0.000\n",
      "epoch 700 : w = 1.993, b = 1.020, loss = 0.000\n",
      "epoch 800 : w = 1.995, b = 1.015, loss = 0.000\n",
      "epoch 900 : w = 1.996, b = 1.011, loss = 0.000\n",
      "epoch 1000 : w = 1.997, b = 1.008, loss = 0.000\n",
      "prediction for f(5) : 10.994\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "y = torch.tensor([[3], [5], [7], [9]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([[5]], dtype=torch.float32)\n",
    "\n",
    "number_of_samples, number_of_features = X.shape\n",
    "print(number_of_samples, number_of_features)\n",
    "\n",
    "input_size = number_of_features\n",
    "output_size = number_of_features\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "n_iters = 1000\n",
    "\n",
    "for epoch in xrange(n_iters):\n",
    "    y_pred = model(X)\n",
    "    l = loss(y_pred, y)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1)%100 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(\"epoch %d : w = %.3f, b = %.3f, loss = %.3f\"%(epoch+1, w, b, l))\n",
    "print(\"prediction for f(5) : %.3f\"%(forward(X_test)))"
   ]
  },
  {
   "source": [
    "1. Make Model (using torch.nn)\n",
    "2. Make Loss (using torch.nn)\n",
    "3. Make Optimizer (using torch.optim)\n",
    "4. Train loop (lr and n_iter)\n",
    "    * forward pass : model(X)\n",
    "    * backward pass : loss.backward()\n",
    "    * update parameters : optimizer.step()\n",
    "    * reset grad : optimizer.grad_zero()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 100 : w = 2.005, b = 0.986, loss = 0.000\nepoch 200 : w = 2.003, b = 0.990, loss = 0.000\nepoch 300 : w = 2.003, b = 0.993, loss = 0.000\nepoch 400 : w = 2.002, b = 0.994, loss = 0.000\nepoch 500 : w = 2.001, b = 0.996, loss = 0.000\nepoch 600 : w = 2.001, b = 0.997, loss = 0.000\nepoch 700 : w = 2.001, b = 0.998, loss = 0.000\nepoch 800 : w = 2.001, b = 0.998, loss = 0.000\nepoch 900 : w = 2.000, b = 0.999, loss = 0.000\nepoch 1000 : w = 2.000, b = 0.999, loss = 0.000\nprediction for f(5) : 11.001\n"
     ]
    }
   ],
   "source": [
    "## OOP\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.lin(X)\n",
    "\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "y = torch.tensor([[3], [5], [7], [9]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([[5]], dtype=torch.float32)\n",
    "\n",
    "number_of_samples, number_of_features = X.shape\n",
    "\n",
    "model = MyModel(input_size, output_size)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "n_iters = 1000\n",
    "\n",
    "for epoch in xrange(n_iters):\n",
    "    y_pred = model(X)\n",
    "    l = loss(y_pred, y)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if (epoch+1)%100 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print(\"epoch %d : w = %.3f, b = %.3f, loss = %.3f\"%(epoch+1, w, b, l))\n",
    "print(\"prediction for f(5) : %.3f\"%(forward(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}